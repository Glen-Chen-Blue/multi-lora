from multilora_system import MultiLoRAEngine
import time

# ============================================================
# 1. åˆå§‹åŒ– Engine
# ============================================================
model_id = "unsloth/Meta-Llama-3.1-8B"
engine = MultiLoRAEngine(
    model_id,
    adapter_slots=1,
    max_batch_size=2,
)

# ============================================================
# 2. è¼‰å…¥ LoRA åˆ° CPU RAM
# ============================================================
engine.load_adapters_to_cpu("./testLoRA")

# ============================================================
# 3. åŠ å…¥è«‹æ±‚ï¼ˆå…¨éƒ¨ç”¨åŒä¸€å€‹ adapterï¼‰
# ============================================================
N_REQ = 2
PROMPT = "Explain Transformer self-attention in one sentence."
ADAPTER_ID = "chat"

for _ in range(N_REQ):
    engine.add_request(PROMPT, adapter_id=ADAPTER_ID)

print("\nğŸš€ é–‹å§‹èª¿åº¦æ¸¬è©¦...")

# ============================================================
# 4. åŸ·è¡Œç”Ÿæˆå¾ªç’°
# ============================================================
start = time.time()
step_count = 0
MAX_STEPS = 3000

while len(engine.finished_results) < N_REQ and step_count < MAX_STEPS:
    has_running = engine.step()
    step_count += 1

    # æ²’æœ‰åœ¨è·‘ã€ä¹Ÿæ²’æœ‰å¾…è™•ç†è«‹æ±‚ï¼Œå°±å¯ä»¥åœ
    if not has_running and not engine.request_queue:
        break

end = time.time()
print(f"èª¿åº¦çµæŸï¼Œç¸½å…±èŠ±è²»æ™‚é–“: {end - start:.2f} ç§’")
print(f"ç¸½ step æ•¸: {step_count}")

# ============================================================
# 5. çµæœé©—è­‰ï¼ˆCPU-onlyï¼‰
# ============================================================
print("\n" + "=" * 50)
for i, res in enumerate(engine.finished_results):
    text = engine.tokenizer.decode(res["tokens"], skip_special_tokens=True)
    aid = res["adapter_id"]
    reason = res["reason"]

    print(f"å®Œæˆ {i+1:02d} [LoRA={aid}, reason={reason}]:")
    print(text)
    print("-" * 50)
